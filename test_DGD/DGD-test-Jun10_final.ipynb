{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/Ziwei-Liu3/Opt4MLProject.git"
      ],
      "metadata": {
        "id": "BATtC7HW_EGy",
        "outputId": "5d10ae9f-170e-49dc-9bec-21231945bbae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Opt4MLProject' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uQ0XDxHDPtPH",
        "outputId": "59ac96cc-2d97-4f56-bf64-21f5b71c0808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "sys.path.append('Opt4MLProject')\n",
        "# from optimizers import *\n",
        "from topology import * \n",
        "from utils import *\n",
        "# from sampling import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(thr, num_nodes, X, grad): #sampledIndex, X_curr\n",
        "  # vector consisting of samples from uniform distribution\n",
        "  sample = np.random.uniform(low = 0.0, high = 1.0, size = (num_nodes))\n",
        "  sampledIndex = sample >= thr\n",
        "  X_curr = X[:, sampledIndex]\n",
        "  grad_curr = grad[sampledIndex, :]\n",
        "  return sampledIndex, X_curr, grad_curr\n",
        "\n",
        "def sampling_grid(thr, num_nodes, X, grad):\n",
        "  # vector consisting of samples from uniform distribution\n",
        "  sample = np.random.uniform(low = 0.0, high = 1.0, size = (num_nodes))\n",
        "  sampledIndex = sample >= thr\n",
        "  while (int(np.sqrt(sampledIndex.sum())) ** 2) != (sampledIndex.sum()):\n",
        "    sample = np.random.uniform(low = 0.0, high = 1.0, size = (num_nodes))\n",
        "    sampledIndex = sample >= thr\n",
        "  X_curr = X[:, sampledIndex]\n",
        "  grad_curr = grad[sampledIndex, :]\n",
        "  return sampledIndex, X_curr, grad_curr\n",
        "\n",
        "def sampling_s(n_sampled_nodes, n_total_nodes, X, grad):\n",
        "  choices = np.random.choice(n_total_nodes, n_sampled_nodes, replace=False)\n",
        "  choices_sorted = choices.sort()\n",
        "  sampledIndex = np.array([False] * n_total_nodes)\n",
        "  sampledIndex[choices_sorted] = True\n",
        "  X_curr = X[:, sampledIndex]\n",
        "  grad_curr = grad[sampledIndex, :]\n",
        "  return sampledIndex, X_curr, grad_curr"
      ],
      "metadata": {
        "id": "Rk9NzDYdR5a9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_step_size(parameters_tuple):\n",
        "  \"\"\"\n",
        "  This function returns the step size suitable for each combination of parameters to produce the best results for each experiment\n",
        "  These step sizes returned were tuned manually\n",
        "  \"\"\"\n",
        "\n",
        "  # lists of value parameters we support\n",
        "  list_of_topologies = [\"ring\", \"centralized\", \"grid\"]\n",
        "  list_of_zetas  = [0, 1, 10]\n",
        "  list_of_sigmas = [0, 1, 100]\n",
        "\n",
        "  assert parameters_tuple[0] in list_of_topologies, f\"toplogy should be inside {list_of_topologies}\"\n",
        "  assert parameters_tuple[1] in list_of_zetas, f\"zeta should be inside {list_of_zetas}\"\n",
        "  assert parameters_tuple[2] in list_of_sigmas, f\"sigma should be inside {list_of_sigmas}\"\n",
        "\n",
        "  # step_size_mapper = {(list_of_topologies[0], list_of_zetas[0], list_of_sigmas[0]): 0.05, \n",
        "  #                     (list_of_topologies[0], list_of_zetas[0], list_of_sigmas[1]): 0.001,\n",
        "  #                     (list_of_topologies[0], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "  #                     (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[0]): 0.0003,\n",
        "  #                     (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[1]): 0.0001,\n",
        "  #                     (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "  #                     (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[0]): 0.0001,\n",
        "  #                     (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[1]): 0.0001,\n",
        "  #                     (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "                      \n",
        "  #                     (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[0]): 0.05, \n",
        "  #                     (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[1]): 0.005,\n",
        "  #                     (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "  #                     (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[0]): 0.01,\n",
        "  #                     (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[1]): 0.01,\n",
        "  #                     (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "  #                     (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[0]): 0.01,\n",
        "  #                     (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[1]): 0.01,\n",
        "  #                     (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "\n",
        "  #                     (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[0]): 0.05, \n",
        "  #                     (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[1]): 0.005,\n",
        "  #                     (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "  #                     (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[0]): 0.001,\n",
        "  #                     (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[1]): 0.003,\n",
        "  #                     (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "  #                     (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[0]): 0.001,\n",
        "  #                     (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[1]): 0.0005,\n",
        "  #                     (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "  #                     }\n",
        "\n",
        "  step_size_mapper = {(list_of_topologies[0], list_of_zetas[0], list_of_sigmas[0]): 0.05, \n",
        "                      (list_of_topologies[0], list_of_zetas[0], list_of_sigmas[1]): 0.001,\n",
        "                      (list_of_topologies[0], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[0]): 0.0001,\n",
        "                      (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[1]): 0.0001,\n",
        "                      (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[0]): 0.00005,\n",
        "                      (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[1]): 0.000075,\n",
        "                      (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "                      \n",
        "                      (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[0]): 0.05, \n",
        "                      (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[1]): 0.001,\n",
        "                      (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[0]): 0.01,\n",
        "                      (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[1]): 0.01,\n",
        "                      (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[0]): 0.01,\n",
        "                      (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[1]): 0.01,\n",
        "                      (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "\n",
        "                      (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[0]): 0.05, \n",
        "                      (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[1]): 0.005,\n",
        "                      (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[0]): 0.001,\n",
        "                      (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[1]): 0.003,\n",
        "                      (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[0]): 0.0005,\n",
        "                      (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[1]): 0.0005,\n",
        "                      (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "                      }\n",
        "\n",
        "  return step_size_mapper[parameters_tuple]"
      ],
      "metadata": {
        "id": "I0ZeaGs3kzOj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probability of node failing \n",
        "def optimize_decentralized(X, A, B, sigma, thr, shuffle, num_iter): \n",
        "    #X, A, B, sigma, thr, shuffle, num_iter = num_iters[i]\n",
        "    # getting dim & number of nodes \n",
        "    num_dim, num_nodes = X.shape\n",
        "    topology_str = [\"ring\", \"centralized\", \"grid\"]\n",
        "    errors = {}\n",
        "    for curr_topology in topology_str:\n",
        "      X_iter = np.copy(X)\n",
        "      errors[curr_topology] = [consensus_distance(X_iter, A, B)]\n",
        "      gamma = return_step_size((curr_topology, zeta, sigma))\n",
        "      for i in range(0, num_iter):\n",
        "          AXmB = (np.einsum(\"ijk,ik->ij\", A, X_iter.T) - B) # shape (num_nodes, num_dim)\n",
        "          grad = np.einsum(\"ijk,ij->ik\", A, AXmB) # shape (num_nodes, num_dim)\n",
        "\n",
        "          # sampled index, sub X, and grad\n",
        "          if curr_topology is not \"grid\":        \n",
        "            sampledIndex, X_curr, grad_curr = sampling(thr, num_nodes, X_iter, grad)\n",
        "          else:\n",
        "            sampledIndex, X_curr, grad_curr = sampling_grid(thr, num_nodes, X_iter, grad)\n",
        "          \n",
        "          numberOfSampled = np.sum(sampledIndex)\n",
        "          # create W \n",
        "          if numberOfSampled != 0:\n",
        "            topology = FixedMixingMatrix(curr_topology, numberOfSampled)\n",
        "            W_curr = topology(i)\n",
        "            noise = np.random.normal(0, np.sqrt(sigma / num_dim), size=X_curr.shape)\n",
        "            if shuffle:\n",
        "              # shuffling \n",
        "              index, X_curr_sh, grad_curr_sh = shuffling(X_curr, grad_curr)\n",
        "              # update\n",
        "              X_temp_sh = X_curr_sh - gamma * (grad_curr_sh.T + noise)\n",
        "              X_next_sh = X_temp_sh.dot(W_curr)\n",
        "              # shuffling_back \n",
        "              X_next = shuffling_back(index, X_next_sh)\n",
        "            else:\n",
        "              X_temp = X_curr - gamma * (grad_curr.T + noise)\n",
        "              X_next = X_temp.dot(W_curr)\n",
        "            X_iter[:, sampledIndex] = X_next\n",
        "          errors[curr_topology] += [consensus_distance(X_iter, A, B)]\n",
        "            # print('X_next:', X_next)\n",
        "    return errors, X_iter\n"
      ],
      "metadata": {
        "id": "WeVzOE0MX4UI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "m78H_Z0YPtPL"
      },
      "outputs": [],
      "source": [
        "def shuffling(X_curr, grad_curr):\n",
        "  num_dim, num_sampled_nodes = X_curr.shape\n",
        "  index = np.arange(num_sampled_nodes)\n",
        "  np.random.shuffle(index)\n",
        "  X_curr_sh = X_curr.T[index].T\n",
        "  grad_curr_sh = grad_curr[index]\n",
        "  return index, X_curr_sh, grad_curr_sh\n",
        "\n",
        "def shuffling_back(index, X_curr_sh):\n",
        "  X_curr_indexed = np.concatenate((index.reshape(1, len(index)), X_curr_sh), axis = 0)\n",
        "  X_curr_indexed = X_curr_indexed[:, X_curr_indexed[0, :].argsort()]\n",
        "  X_curr_indexed = X_curr_indexed[1:, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "r81eB4N-PtPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46296ed8-75d3-43c3-89c5-40b475c15883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "zetas = [0, 1, 10]\n",
        "sigmas = [0, 1, 100]\n",
        "all_thrs = np.linspace(0, 1, num=3)\n",
        "num_nodes = 25\n",
        "num_dim = 50\n",
        "shuffle = False\n",
        "X = np.ones(shape=(num_dim, num_nodes))\n",
        "all_combinations = list(itertools.product(sigmas, zetas))\n",
        "num_iters = [1000, 10000, 15000] + ([12000] * 6)\n",
        "\n",
        "\n",
        "for thr in tqdm(all_thrs[1:]):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(20,20))\n",
        "\n",
        "  for i, (sigma, zeta) in enumerate(all_combinations):\n",
        "    # initialize data\n",
        "    np.random.seed(10)\n",
        "    A, B = generate_functions(num_nodes, num_dim, zeta)\n",
        "    errors, _ = optimize_decentralized(X, A, B, sigma, thr, shuffle, num_iter = num_iters[i])\n",
        "\n",
        "    axe = ax[i//3][i%3]\n",
        "    axe.axhline(y=1e-5, linestyle='dashed', color='k')\n",
        "    axe.set_ylim([1e-6, 10e0])\n",
        "    axe.set_yscale('log')\n",
        "    if(i > 2):\n",
        "      axe.set_xscale('log')\n",
        "    axe.set_title(f'sigma={sigma}, zeta={zeta}')\n",
        "    for k, v in errors.items():  \n",
        "      axe.plot(errors[k], label=k, alpha=0.4)\n",
        "    axe.legend()\n",
        "  fig.savefig(f'baseline_{thr}_threshold.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pIB-hK1-LoLT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DGD-test.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}