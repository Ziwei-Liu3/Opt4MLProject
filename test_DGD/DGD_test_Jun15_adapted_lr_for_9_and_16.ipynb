{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ziwei-Liu3/Opt4MLProject/blob/main/DGD_test_Jun15_adapted_lr_for_9_and_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/Ziwei-Liu3/Opt4MLProject.git"
      ],
      "metadata": {
        "id": "BATtC7HW_EGy",
        "outputId": "f5e33acc-51f4-4d96-d271-6e9b79594cc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Opt4MLProject'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 87 (delta 34), reused 30 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (87/87), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uQ0XDxHDPtPH"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "sys.path.append('Opt4MLProject')\n",
        "# from optimizers import *\n",
        "from Opt4MLProject.topology import * \n",
        "from Opt4MLProject.utils import *\n",
        "# from sampling import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_step_size(parameters_tuple):\n",
        "  \"\"\"\n",
        "  This function returns the step size suitable for each combination of parameters to produce the best results for each experiment\n",
        "  These step sizes returned were tuned manually\n",
        "  \"\"\"\n",
        "\n",
        "  # lists of value parameters we support\n",
        "  list_of_topologies = [\"ring\", \"centralized\", \"grid\"]\n",
        "  list_of_zetas  = [0, 1, 10]\n",
        "  list_of_sigmas = [0, 1, 100]\n",
        "\n",
        "  assert parameters_tuple[0] in list_of_topologies, f\"toplogy should be inside {list_of_topologies}\"\n",
        "  assert parameters_tuple[1] in list_of_zetas, f\"zeta should be inside {list_of_zetas}\"\n",
        "  assert parameters_tuple[2] in list_of_sigmas, f\"sigma should be inside {list_of_sigmas}\"\n",
        "\n",
        "  step_size_mapper = {(list_of_topologies[0], list_of_zetas[0], list_of_sigmas[0]): 0.05,\n",
        "                      (list_of_topologies[0], list_of_zetas[0], list_of_sigmas[1]): 0.003,\n",
        "                      (list_of_topologies[0], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[0]): 0.00012,\n",
        "                      (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[1]): 0.0001,\n",
        "                      (list_of_topologies[0], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[0]): 0.000065,\n",
        "                      (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[1]): 0.00005,\n",
        "                      (list_of_topologies[0], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "                      \n",
        "                      (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[0]): 0.05, \n",
        "                      (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[1]): 0.007,\n",
        "                      (list_of_topologies[1], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[0]): 0.01,\n",
        "                      (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[1]): 0.005,\n",
        "                      (list_of_topologies[1], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[0]): 0.01,\n",
        "                      (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[1]): 0.003,\n",
        "                      (list_of_topologies[1], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "\n",
        "                      (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[0]): 0.05, \n",
        "                      (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[1]): 0.005,\n",
        "                      (list_of_topologies[2], list_of_zetas[0], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[0]): 0.001,\n",
        "                      (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[1]): 0.0015,\n",
        "                      (list_of_topologies[2], list_of_zetas[1], list_of_sigmas[2]): 0.0001,\n",
        "                      (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[0]): 0.0005,\n",
        "                      (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[1]): 0.0005,\n",
        "                      (list_of_topologies[2], list_of_zetas[2], list_of_sigmas[2]): 0.0001,\n",
        "                      }\n",
        "\n",
        "  return step_size_mapper[parameters_tuple]"
      ],
      "metadata": {
        "id": "I0ZeaGs3kzOj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(thr, num_nodes, X, grad): #sampledIndex, X_curr\n",
        "  # vector consisting of samples from uniform distribution\n",
        "  sample = np.random.uniform(low = 0.0, high = 1.0, size = (num_nodes))\n",
        "  sampledIndex = sample >= thr\n",
        "  X_curr = X[:, sampledIndex]\n",
        "  grad_curr = grad[sampledIndex, :]\n",
        "  return sampledIndex, X_curr, grad_curr\n",
        "\n",
        "def sampling_grid(thr, num_nodes, X, grad):\n",
        "  # vector consisting of samples from uniform distribution\n",
        "  sample = np.random.uniform(low = 0.0, high = 1.0, size = (num_nodes))\n",
        "  sampledIndex = sample >= thr\n",
        "  while (int(np.sqrt(sampledIndex.sum())) ** 2) != (sampledIndex.sum()):\n",
        "    sample = np.random.uniform(low = 0.0, high = 1.0, size = (num_nodes))\n",
        "    sampledIndex = sample >= thr\n",
        "  X_curr = X[:, sampledIndex]\n",
        "  grad_curr = grad[sampledIndex, :]\n",
        "  return sampledIndex, X_curr, grad_curr\n",
        "\n",
        "def sampling_s(n_sampled_nodes, n_total_nodes, X, grad):\n",
        "  n_total_nodes_line = np.arange(n_total_nodes)\n",
        "  choices = np.random.choice(n_total_nodes_line, n_sampled_nodes, replace=False)\n",
        "  sampledIndex = np.array([False] * n_total_nodes)\n",
        "  sampledIndex[choices] = True\n",
        "  X_curr = X[:, sampledIndex]\n",
        "  grad_curr = grad[sampledIndex, :]\n",
        "  return sampledIndex, X_curr, grad_curr"
      ],
      "metadata": {
        "id": "Rk9NzDYdR5a9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probability of node failing \n",
        "def optimize_decentralized(X, A, B, sigma, sampling_method, sampling_param, shuffle, num_iter): \n",
        "    # getting dim & number of nodes \n",
        "    num_dim, num_nodes = X.shape\n",
        "    topology_str = [\"ring\", \"centralized\", \"grid\"]\n",
        "    errors = {}\n",
        "    for curr_topology in topology_str:\n",
        "      X_iter = np.copy(X)\n",
        "      errors[curr_topology] = [consensus_distance(X_iter, A, B)]\n",
        "      \n",
        "      gamma = return_step_size((curr_topology, zeta, sigma))\n",
        "      for i in range(0, num_iter):\n",
        "          AXmB = (np.einsum(\"ijk,ik->ij\", A, X_iter.T) - B) # shape (num_nodes, num_dim)\n",
        "          grad = np.einsum(\"ijk,ij->ik\", A, AXmB) # shape (num_nodes, num_dim)\n",
        "\n",
        "          if sampling_method == \"failure_prob\":\n",
        "            thr = sampling_param\n",
        "            # sampled index, sub X, and grad\n",
        "            if curr_topology is not \"grid\":        \n",
        "              sampledIndex, X_curr, grad_curr = sampling(thr, num_nodes, X_iter, grad)\n",
        "            else:\n",
        "              sampledIndex, X_curr, grad_curr = sampling_grid(thr, num_nodes, X_iter, grad)\n",
        "\n",
        "          elif sampling_method == \"fixed_s\":\n",
        "            s = sampling_param\n",
        "            assert int(np.sqrt(s)) ** 2 == s, \"number of workers should be square of an int\"\n",
        "            sampledIndex, X_curr, grad_curr = sampling_s(s, num_nodes, X_iter, grad)\n",
        "          numberOfSampled = np.sum(sampledIndex)\n",
        "          # create W \n",
        "          if numberOfSampled != 0:\n",
        "            topology = FixedMixingMatrix(curr_topology, numberOfSampled)\n",
        "            W_curr = topology(i)\n",
        "            noise = np.random.normal(0, np.sqrt(sigma / num_dim), size=X_curr.shape)\n",
        "            if shuffle:\n",
        "              # shuffling \n",
        "              index, X_curr_sh, grad_curr_sh = shuffling(X_curr, grad_curr)\n",
        "              # update\n",
        "              X_temp_sh = X_curr_sh - gamma * (grad_curr_sh.T + noise)\n",
        "              X_next_sh = X_temp_sh.dot(W_curr)\n",
        "              # shuffling_back \n",
        "              X_next = shuffling_back(index, X_next_sh)\n",
        "            else:\n",
        "              X_temp = X_curr - gamma * (grad_curr.T + noise)\n",
        "              X_next = X_temp.dot(W_curr)\n",
        "            X_iter[:, sampledIndex] = X_next\n",
        "          errors[curr_topology] += [consensus_distance(X_iter, A, B)]\n",
        "            # print('X_next:', X_next)\n",
        "    return errors, X_iter\n"
      ],
      "metadata": {
        "id": "LDUFViFjXddB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m78H_Z0YPtPL"
      },
      "outputs": [],
      "source": [
        "def shuffling(X_curr, grad_curr):\n",
        "  num_dim, num_sampled_nodes = X_curr.shape\n",
        "  index = np.arange(num_sampled_nodes)\n",
        "  np.random.shuffle(index)\n",
        "  X_curr_sh = X_curr.T[index].T\n",
        "  grad_curr_sh = grad_curr[index]\n",
        "  return index, X_curr_sh, grad_curr_sh\n",
        "\n",
        "def shuffling_back(index, X_curr_sh):\n",
        "  X_curr_indexed = np.concatenate((index.reshape(1, len(index)), X_curr_sh), axis = 0)\n",
        "  X_curr_indexed = X_curr_indexed[:, X_curr_indexed[0, :].argsort()]\n",
        "  X_curr_indexed = X_curr_indexed[1:, :]\n",
        "  return X_curr_indexed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "r81eB4N-PtPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e564e6f4-2623-4f20-d987-87b489383db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 11%|█         | 1/9 [00:09<01:13,  9.23s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "zetas = [0, 1, 10]\n",
        "sigmas = [0, 1, 100]\n",
        "num_nodes = 25\n",
        "num_dim = 50\n",
        "shuffle = True \n",
        "X = np.ones(shape=(num_dim, num_nodes))\n",
        "all_combinations = list(itertools.product(sigmas, zetas))\n",
        "\n",
        "# for 25\n",
        "# num_iters = [1000, 10000, 15000] + ([14000] * 6)\n",
        "# num_iters[5] = 20000\n",
        "\n",
        "# for 16\n",
        "# num_iters = [1000, 15000, 30000] + ([25000] * 6)\n",
        "# num_iters[5] = 60000\n",
        "\n",
        "# for 9\n",
        "num_iters = [1000, 30000, 50000] + ([100000] * 6)\n",
        "\n",
        "# choose the sampling method \n",
        "sampling_methods = [\"failure_prob\", \"fixed_s\"] # \n",
        "all_s = [9]\n",
        "all_thrs = [0] #np.linspace(0, 1, num=3)\n",
        "sampling_method = \"fixed_s\" # \"failure_prob\" #\n",
        "sampling_param_options = all_s # all_thrs # \n",
        "\n",
        "for sampling_param in tqdm(sampling_param_options):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(20,20))\n",
        "\n",
        "  for i, (sigma, zeta) in enumerate(tqdm(all_combinations)):\n",
        "    # initialize data\n",
        "    np.random.seed(10)\n",
        "    A, B = generate_functions(num_nodes, num_dim, zeta)\n",
        "    # errors, _ = optimize_decentralized(X, A, B, sigma, thr, shuffle, num_iter = num_iters[i])\n",
        "    errors, _ = optimize_decentralized(X, A, B, sigma, sampling_method, sampling_param, shuffle, num_iter = num_iters[i])\n",
        "\n",
        "    axe = ax[i//3][i%3]\n",
        "    axe.axhline(y=1e-5, linestyle='dashed', color='k')\n",
        "    axe.set_ylim([1e-6, 10e0])\n",
        "    axe.set_yscale('log')\n",
        "    if(i > 2):\n",
        "      axe.set_xscale('log')\n",
        "    axe.set_title(f'sigma={sigma}, zeta={zeta}')\n",
        "    for k, v in errors.items():  \n",
        "      axe.plot(errors[k], label=k, alpha=0.4, linewidth=3)\n",
        "    axe.legend()\n",
        "  if sampling_method == \"failure_prob\":\n",
        "    fig.savefig(f'{sampling_param}_threshold_shuffle_{shuffle}.jpg')\n",
        "  elif sampling_method == \"fixed_s\":\n",
        "    fig.savefig(f'{sampling_param}_workers_shuffle_{shuffle}.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tdloEbxD6fuR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DGD_test_Jun10_lastVersion (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}